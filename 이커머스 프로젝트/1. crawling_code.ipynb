{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867d58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests                  #파이썬과 URL이 소통하는 창구\n",
    "from bs4 import BeautifulSoup    #HTML 객체를 parsing하기 위한 라이브러리\n",
    "import time \n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a5333a",
   "metadata": {},
   "source": [
    "### 엑셀 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f049e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#엑셀파일 생성\n",
    "wb = openpyxl.Workbook(\"올리브영_판매랭킹_스킨케어.xlsx\")        \n",
    "ws = wb.create_sheet(\"Sheet1\")             \n",
    "ws.append(['브랜드','상품명','카테고리','정가','할인가','아이디','별점','피부정보','피부타입','피부고민','자극도'])  #컬럼명 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2202a3e1",
   "metadata": {},
   "source": [
    "### 올리브영 스킨케어 랭킹 링크를 main_url로 두고 5위까지 제품 상세 링크를 sub_url에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a960ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://www.oliveyoung.co.kr/store/main/getBestList.do?dispCatNo=900000100100001&fltDispCatNo=10000010001&pageIdx=1&rowsPerPage=8\"\n",
    "\n",
    "response = requests.get(main_url)  # main_url의 링크를 request.get으로 response에 가져온다\n",
    "html = response.text               # get 응답의 요청을 텍스트화 한다\n",
    "soup = BeautifulSoup(html, 'html.parser') # HTML parser를 사용하여 HTML 코드를 파싱한다\n",
    "\n",
    "links = soup.select(\"li > div > a\") # li.flag로 하면 좌측에 있는 1개씩만 긁어와서 총 25개만 긁어오게 됨\n",
    "\n",
    "#rank=\n",
    "\n",
    "sub_url = []\n",
    "\n",
    "for link in links:                  #for반복문을 활용하여 5위까지 제품별 상세링크 sub_url에 저장\n",
    "    href_value = link.get(\"href\")\n",
    "    sub_url.append(href_value)      # sub_url 리스트에 링크 추가\n",
    "\n",
    "sub_url = sub_url[:5] # 5위까지 제품 상세 링크를 sub_url에 저장\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905dc1dd",
   "metadata": {},
   "source": [
    "### 크롤링 함수\n",
    "제품 상세 페이지에서 상단 제품정보(브랜드명,상품명,카테고리,정가,할인가)와  \n",
    "하단의 리뷰고객 좌픅정보(아이디,별점,피부정보)와 우측정보(피부타입,피부고민,자극도)를 가져와 ws에 추가한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9644353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_info():\n",
    "\n",
    "    #브랜드\n",
    "    try:\n",
    "        brand = driver.find_element(By.CSS_SELECTOR, '#moveBrandShop').text\n",
    "    except:\n",
    "        brand =\"없음\"\n",
    "\n",
    "    #상품명\n",
    "    try:\n",
    "         p_name = driver.find_element(By.CSS_SELECTOR, '#Contents > div.prd_detail_box.renew > div.right_area > div > p.prd_name').text\n",
    "    except:\n",
    "        p_name=\"없음\"\n",
    "\n",
    "    #카테고리\n",
    "    try:\n",
    "        p_category = driver.find_element(By.CSS_SELECTOR, '#dtlCatNm').text\n",
    "    except:\n",
    "        p_category=\"없음\"\n",
    "\n",
    "    #정가\n",
    "    try:\n",
    "        price = driver.find_element(By.CSS_SELECTOR, '#Contents > div.prd_detail_box.renew > div.right_area > div > div.price > span.price-1 > strike').text\n",
    "    except:\n",
    "        price=0\n",
    "\n",
    "    #할인가\n",
    "    try:\n",
    "        discount = driver.find_element(By.CSS_SELECTOR, '#Contents > div.prd_detail_box.renew > div.right_area > div > div.price > span.price-2 > strong').text\n",
    "    except:\n",
    "        discount=0\n",
    "            \n",
    "\n",
    "    for j in range(1, 11, 1):\n",
    "        #고객 아이디\n",
    "        try:\n",
    "            _id = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j}) > div.info > div > p.info_user > a.id').text\n",
    "        except:\n",
    "            _id =\"없음\"\n",
    "\n",
    "        #별점\n",
    "        try:\n",
    "            _star = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j}) > div.review_cont > div.score_area > span.review_point > span').text\n",
    "        except:\n",
    "            _star=\"없음\"\n",
    "\n",
    "        #고객 피부 정보\n",
    "        try:\n",
    "            _info = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j}) > div.info > div > p.tag').text\n",
    "        except:\n",
    "            _info = \"없음\"\n",
    "\n",
    "        #피부 타입\n",
    "        try:\n",
    "            skin_type = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j}) > div.review_cont > div.poll_sample > dl:nth-child(1) > dd > span').text\n",
    "        except:\n",
    "            skin_type = \"없음\"\n",
    "            \n",
    "        #피부 고민\n",
    "        try:\n",
    "            skin_trouble = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j}) > div.review_cont > div.poll_sample > dl:nth-child(2) > dd > span').text\n",
    "        except:\n",
    "            skin_trouble = \"없음\"\n",
    "        #자극도\n",
    "        try:\n",
    "            skin_irritation = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j}) > div.review_cont > div.poll_sample > dl:nth-child(3) > dd > span').text\n",
    "        except:\n",
    "            skin_irritation = \"없음\"\n",
    "            \n",
    "        #엑셀 데이터 쌓기\n",
    "        ws.append([brand,p_name,p_category,price,discount,_id, _star, _info, skin_type, skin_trouble, skin_irritation])\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4d340",
   "metadata": {},
   "source": [
    "### 웹페이지 해당 주소로 이동하여 크롤링함수를 실행하는 반복문\n",
    "1. sub_url을 가져와 chrome을 실행\n",
    "2. 리뷰버튼 클릭  \n",
    "3. 화면 맨 아래까지 스크롤\n",
    "4. 10페이지 이하일 때 : 10페이지 크롤링 한 후 다음페이지 화살표 버튼 누르기 , 마지막 페이지인 경우 last_page==True\n",
    "5. 11페이지부터 다른 규칙을 적용하여 다음페이지로 이동하게 만들기, 마지막 페이지인 경우 last_page==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "#웹페이지 해당 주소 이동\n",
    "for i in range(0,5):          #전체 제품을 한번에 크롤링하지 않고 나눠서 크롤링 할 경우 sub_url 인덱스 고려해서 range숫자 변경\n",
    "\n",
    "    driver.implicitly_wait(10)  #웹페이지 로딩 될때까지 5초는 기다림\n",
    "    driver.maximize_window()   #화면 최대화\n",
    "    driver.get(sub_url[i])          \n",
    "    time.sleep(3)\n",
    "\n",
    "    #리뷰버튼 클릭\n",
    "    rv = driver.find_element(By.CSS_SELECTOR, \"#reviewInfo > a\")\n",
    "    rv.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    #리뷰 하단 끝까지 스크롤하는 함수 (빈칸없음.그대로 코드 사용가능)\n",
    "    before_h = driver.execute_script(\"return window.scrollY\")         #스크롤 전 높이\n",
    "    #화면 맨아래까지 스크롤\n",
    "    while True:\n",
    "        driver.find_element(By.CSS_SELECTOR,\"body\").send_keys(Keys.END)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        #스크롤 후 높이\n",
    "        after_h = driver.execute_script(\"return window.scrollY\")\n",
    "\n",
    "        #스크롤 값이 같으면 스크롤 멈춤\n",
    "        if after_h == before_h:\n",
    "            break\n",
    "        before_h = after_h   \n",
    "\n",
    "    last_page=False\n",
    "    \n",
    "    for k in range(1,101):  #100페이지 크롤링 한다고 했을 때 (상품당 최대 100페이지까지 있음)\n",
    "        \n",
    "        customer_info() # 해당 페이지에 있는 10개의 리뷰에 관한 데이터 크롤링하기\n",
    "        \n",
    "        #마지막 페이지면 종료\n",
    "        if last_page == True:\n",
    "            break\n",
    "\n",
    "        #페이지 숫자 10이하 일 때\n",
    "        if k < 11:\n",
    "            try:    \n",
    "                if k != 10:\n",
    "                    # 다음 페이지로 넘어가기\n",
    "                    num = k + 1\n",
    "                    next_page = driver.find_element(By.CSS_SELECTOR, f'#gdasContentsArea > div > div.pageing > a:nth-child({num})')\n",
    "                    next_page.click()\n",
    "                    \n",
    "                elif k == 10:          # 10페이지 크롤링 한 후에 다음페이지로 가는 화살표 버튼 클릭\n",
    "                    next_ten = driver.find_element(By.CSS_SELECTOR, \"#gdasContentsArea > div > div.pageing > a.next\")\n",
    "                    next_ten.click()\n",
    "                    \n",
    "            except: # 오류가 발생할 경우는 마지막 페이지라서 다음 페이지가 없는 경우\n",
    "                last_page = True # 다음 시행에 for 문이 종료될 수 있도록 last_page를 True로 변경\n",
    "                    \n",
    "\n",
    "       #페이지 숫자 11이상 일 때  (규칙을 찾아 각 페이지 크롤링 후 다음 페이지로 이동하도록 코드 작성)        \n",
    "        elif k > 10 :\n",
    "            try:\n",
    "                if k % 10 != 0:\n",
    "                    # 다음 페이지로 넘어가기 (10 이전과 다르게 11은 child(2), 12는 child(3)이다)\n",
    "                    num = (k % 10) + 2 # 규칙에 맞게 index를 설정해준다\n",
    "                    next_page = driver.find_element(By.CSS_SELECTOR, f'#gdasContentsArea > div > div.pageing > a:nth-child({num})')\n",
    "                    next_page.click()\n",
    "                \n",
    "                elif k % 10 == 0:    # 10페이지 크롤링 한 후에 다음페이지로 가는 화살표 버튼 클릭\n",
    "                    next_ten = driver.find_element(By.CSS_SELECTOR, \"#gdasContentsArea > div > div.pageing > a.next\")\n",
    "                    next_ten.click()\n",
    "\n",
    "            except: # 오류가 발생할 경우는 마지막 페이지라서 다음 페이지가 없는 경우\n",
    "                last_page = True # 다음 시행에 for 문이 종료될 수 있도록 last_page를 True로 변경\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362fa376",
   "metadata": {},
   "source": [
    "### 크롤링한 결과를 엑셀에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d616c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save(\"올리브영_판매랭킹_스킨케어.xlsx\") # 상단에서 만든 엑셀 파일명과 동일"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
